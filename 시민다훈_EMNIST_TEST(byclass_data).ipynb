{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "uLt1hKtZvLgJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLt1hKtZvLgJ",
    "outputId": "51c92dd0-a2f4-4bd3-aad6-0915c25f6d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 16 16:58:49 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.23       Driver Version: 511.23       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   47C    P8    25W / 170W |    519MiB / 12288MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1076    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A      2172    C+G   ...Roaming\\Zoom\\bin\\Zoom.exe    N/A      |\n",
      "|    0   N/A  N/A      5800    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5816    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6160    C+G                                   N/A      |\n",
      "|    0   N/A  N/A      6848    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      7088    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8588    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10944    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     11180    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "MjiOwnBHvOrt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjiOwnBHvOrt",
    "outputId": "0e778766-d1ed-42a8-96d7-a8e78f8c203b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 34.1 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080c6dec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "080c6dec",
    "outputId": "70b42d45-b14b-4f36-ae85-46229eae33ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  0.24.2\n",
      "TF version:  2.8.0\n",
      "GPU installed:  True\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58748ecd",
   "metadata": {
    "id": "58748ecd"
   },
   "source": [
    "# DATA EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7f5193",
   "metadata": {
    "id": "ed7f5193"
   },
   "outputs": [],
   "source": [
    "#byclass_train = pd.read_csv(\"/content/drive/MyDrive/emnist-byclass-train.csv\")\n",
    "byclass_test = pd.read_csv(\"C:/Users/user/Favorites/EMNIST_test_competition.csv\")\n",
    "\n",
    "#mapp = pd.read_csv(\"/content/drive/MyDrive/emnist-byclass-mapping.txt\", delimiter = ' ', index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a81d7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "e9a81d7f",
    "outputId": "cda7396d-8ec6-43b0-b908-53bc6d9499e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>1.2</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>...</th>\n",
       "      <th>0.438</th>\n",
       "      <th>0.439</th>\n",
       "      <th>0.440</th>\n",
       "      <th>0.441</th>\n",
       "      <th>0.442</th>\n",
       "      <th>0.443</th>\n",
       "      <th>0.444</th>\n",
       "      <th>0.445</th>\n",
       "      <th>0.446</th>\n",
       "      <th>0.447</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   14  0  0.1  0.2  0.3    1  1.1  1.2  0.4  0.5  ...  0.438  0.439  0.440  \\\n",
       "0  52  0    0  221  221  221  208  208  208    0  ...      0      0      0   \n",
       "1  17  0    0    0    0    0    0    1    1    1  ...      1      1      1   \n",
       "2  48  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  10  0    0    0    0    0    0    0    0    0  ...     84     84     84   \n",
       "4  49  1    4    4    4    2    2    2    0    0  ...      1      0      0   \n",
       "\n",
       "   0.441  0.442  0.443  0.444  0.445  0.446  0.447  \n",
       "0      0      0      2      2      2      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3    127    127    127    255    255    255    254  \n",
       "4      0      2      2      2      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byclass_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QByFFSaYGZQZ",
   "metadata": {
    "id": "QByFFSaYGZQZ"
   },
   "source": [
    "# DATA Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cebea0f2",
   "metadata": {
    "id": "cebea0f2"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_test = byclass_test.iloc[:,1:]\n",
    "y_test = byclass_test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136f3641",
   "metadata": {
    "id": "136f3641"
   },
   "outputs": [],
   "source": [
    "# Normalise data and reshape\n",
    "\n",
    "x_test = np.array(x_test) / 255.0\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec4a2b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fec4a2b1",
    "outputId": "5e424250-234e-43eb-98b9-9f6a81f1fa61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.8666667 , ..., 0.00784314, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7624357e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7624357e",
    "outputId": "e5421dfc-9b43-4bd9-f6d1-d05deca72522"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62305fbf",
   "metadata": {
    "id": "62305fbf"
   },
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "number_of_classes = 62\n",
    "\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9973bf53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9973bf53",
    "outputId": "b6587a67-4edb-43fe-ee40-1dc68e650ad3"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9054af",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80a8c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "new_model = tf.keras.models.load_model('byclass_vgg5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e7c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 40ms/step - loss: 13.8908 - accuracy: 0.2269\n",
      "\n",
      "\n",
      "test_loss, test_acc:  13.890804290771484 0.22689075767993927\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = new_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"test_loss, test_acc: \",test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c467b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#빠른거!\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "new_model = tf.keras.models.load_model('select_model_vgg5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194d8289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 45ms/step - loss: 12.3873 - accuracy: 0.1933\n",
      "\n",
      "\n",
      "test_loss, test_acc:  12.387263298034668 0.19327731430530548\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = new_model.evaluate(x_test, y_test)\n",
    "print(\"\\n\")\n",
    "print(\"test_loss, test_acc: \",test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# terminate_time = time.time() -start\n",
    "\n",
    "# hours, mu, ss = hms(terminate_time)\n",
    "# print('inf time: ', hours, 'h', mu, 'm',ss,'s')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "58748ecd",
    "QByFFSaYGZQZ",
    "9b2f15da",
    "20e16394"
   ],
   "machine_shape": "hm",
   "name": "EMNIST_baselineOnly(byclass_data).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
