{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11418821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version:  0.24.2\n",
      "TF version:  2.6.2\n",
      "No GPU was detected. CNNs can be very slow without a GPU.\n",
      "GPU installed:  True\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "print(\"sklearn version: \", sklearn.__version__)\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TF version: \", tf.__version__)\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# GPU test\n",
    "print(\"GPU installed: \",tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# To prevent \"CUDNN_STATUS_ALLOC_FAILED\" error with GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "    \n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"cnn\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3acc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0635bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file이 있는 path로 이동\n",
    "os.chdir(\"./emnist\")\n",
    "# os.chdir('/content/drive/MyDrive/ANN/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f784aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EMNIST dataset\n",
    "import pandas as pd\n",
    "# import gzip\n",
    "\n",
    "byclass_train = pd.read_csv(\"./emnist-byclass-train.csv\")\n",
    "byclass_test = pd.read_csv(\"./emnist-byclass-test.csv\")\n",
    "mapp = pd.read_csv(\"./emnist-byclass-mapping.txt\", \n",
    "                   delimiter = ' ', index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389a1d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(697931, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame\n",
    "byclass_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b38ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.466</th>\n",
       "      <th>0.467</th>\n",
       "      <th>0.468</th>\n",
       "      <th>0.469</th>\n",
       "      <th>0.470</th>\n",
       "      <th>0.471</th>\n",
       "      <th>0.472</th>\n",
       "      <th>0.473</th>\n",
       "      <th>0.474</th>\n",
       "      <th>0.475</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   35  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.466  0.467  0.468  \\\n",
       "0  36  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1   6  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2   3  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  22  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  38  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.469  0.470  0.471  0.472  0.473  0.474  0.475  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byclass_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce1db57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116322, 785)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byclass_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f8d327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.652</th>\n",
       "      <th>0.653</th>\n",
       "      <th>0.654</th>\n",
       "      <th>0.655</th>\n",
       "      <th>0.656</th>\n",
       "      <th>0.657</th>\n",
       "      <th>0.658</th>\n",
       "      <th>0.659</th>\n",
       "      <th>0.660</th>\n",
       "      <th>0.661</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   18  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.652  0.653  0.654  \\\n",
       "0  36  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1   0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2   3  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  33  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  30  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.655  0.656  0.657  0.658  0.659  0.660  0.661  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byclass_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e8409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes:  62\n"
     ]
    }
   ],
   "source": [
    "classes = len(byclass_train['35'].value_counts())\n",
    "print('number of classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e777e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label만 뽑아내기\n",
    "y_train_full = byclass_train[['35']]\n",
    "\n",
    "# data만 뽑아내기\n",
    "X_train_full = byclass_train.drop(['35'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48440888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test에 대해서 반복\n",
    "y_test = byclass_test[['18']]\n",
    "X_test = byclass_test.drop(['18'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b225571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas DF를 numpy로 바꿔주기\n",
    "X_train_full, y_train_full = X_train_full.to_numpy(), y_train_full.to_numpy()\n",
    "X_test, y_test = X_test.to_numpy(), y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51ae00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "X_train_full = X_train_full/255.\n",
    "X_test = X_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb2458c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.astype('float32')\n",
    "X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26324939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (697931, 28, 28, 1)\n",
      "X_test.shape: (116322, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reshape image for CNN\n",
    "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
    "\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(\"X_train.shape:\", X_train_full.shape)\n",
    "print(\"X_test.shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff17ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes:  62\n",
      "y_train:  (697931, 62)\n",
      "y_test:  (116322, 62)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print('number of classes: ', classes)\n",
    "\n",
    "# One hot encoding\n",
    "y_train_full = to_categorical(y_train_full, classes)\n",
    "y_test = to_categorical(y_test, classes)\n",
    "print(\"y_train: \", y_train_full.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4cae8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train and valid dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1242af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(558344, 28, 28, 1) float64\n",
      "(558344, 62) float32\n"
     ]
    }
   ],
   "source": [
    "# Print shape and datatype of X_rain_full\n",
    "\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d533e",
   "metadata": {},
   "source": [
    "# Modeling-dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cebd536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 시현: ResNet\\n\\t병민: 파밍중\\n\\t다경: VGG\\n\\t재훈: inceptionNet(구글넷)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 무슨 모델 쓸~까요\n",
    "\"\"\" 시현: ResNet\n",
    "\t병민: 파밍중\n",
    "\t다경: VGG\n",
    "\t재훈: inceptionNet(구글넷)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d5ccae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Dense, concatenate, AveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "# DenseNet\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "051eb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet:\n",
    "    def __init__(self, input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, nb_classes=None,\n",
    "                 dropout_rate=None, bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n",
    "\n",
    "        # Checks\n",
    "        if nb_classes == None:\n",
    "            raise Exception(\n",
    "                'Please define number of classes (e.g. num_classes=10). This is required for final softmax.')\n",
    "\n",
    "        if compression <= 0.0 or compression > 1.0:\n",
    "            raise Exception('Compression have to be a value between 0.0 and 1.0.')\n",
    "\n",
    "        if type(dense_layers) is list:\n",
    "            if len(dense_layers) != dense_blocks:\n",
    "                raise AssertionError('Number of dense blocks have to be same length to specified layers')\n",
    "        elif dense_layers == -1:\n",
    "            dense_layers = int((depth - 4) / 3)\n",
    "            if bottleneck:\n",
    "                dense_layers = int(dense_layers / 2)\n",
    "            dense_layers = [dense_layers for _ in range(dense_blocks)]\n",
    "        else:\n",
    "            dense_layers = [dense_layers for _ in range(dense_blocks)]\n",
    "\n",
    "        self.dense_blocks = dense_blocks\n",
    "        self.dense_layers = dense_layers\n",
    "        self.input_shape = input_shape\n",
    "        self.growth_rate = growth_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.bottleneck = bottleneck\n",
    "        self.compression = compression\n",
    "        self.nb_classes = nb_classes\n",
    "        \n",
    "    def build_model(self):\n",
    "        img_input = Input(shape=self.input_shape, name='img_input')\n",
    "        nb_channels = self.growth_rate\n",
    "        \n",
    "        x = Conv2D(2*self.growth_rate, (3,3), \n",
    "                   padding='same', strides = (1,1), \n",
    "                   kernel_regularizer=keras.regularizers.l2(self.weight_decay))(img_input)\n",
    "        \n",
    "        for block in range(self.dense_blocks-1):\n",
    "            x, nb_channels = self.dense_block(x, self.dense_layers[block], nb_channels, self.growth_rate,\n",
    "                                              self.dropout_rate, self.bottleneck, self.weight_decay)\n",
    "            \n",
    "            x = self.transition_layer(x, nb_channels, self.dropout_rate, self.compression, self.weight_decay)\n",
    "            nb_channels = int(nb_channels*self.compression)\n",
    "            \n",
    "        x, nb_channels = self.dense_block(x, self.dense_layers[-1], nb_channels, self.growth_rate, self.dropout_rate, self.weight_decay)\n",
    "        \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        prediction = Dense(self.nb_classes, activation='softmax')(x)\n",
    "        \n",
    "        return Model(inputs=img_input, outputs=prediction, name='densenet')\n",
    "        \n",
    "    def dense_block(self, x, nb_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n",
    "        for i in range(nb_layers):\n",
    "            cb = self.convolution_block(x, growth_rate, dropout_rate, bottleneck)\n",
    "            nb_channels += growth_rate\n",
    "            x = concatenate([cb,x])\n",
    "            \n",
    "        return x, nb_channels\n",
    "    \n",
    "    def convolution_block(self, x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):       \n",
    "\n",
    "        # Bottleneck\n",
    "        if bottleneck:\n",
    "            bottleneckWidth = 4\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Conv2D(nb_channels * bottleneckWidth, (1, 1),\n",
    "                                     kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
    "            # Dropout\n",
    "            if dropout_rate:\n",
    "                x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        # Standard (BN-ReLU-Conv)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(nb_channels, (3, 3), padding='same')(x)\n",
    "\n",
    "        # Dropout\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def transition_layer(self, x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(int(nb_channels * compression), (1, 1), padding='same',\n",
    "                                 kernel_regularizer=keras.regularizers.l2(weight_decay))(x)\n",
    "\n",
    "        # Adding dropout\n",
    "        if dropout_rate:\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53cf173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = DenseNet((28,28,1), nb_classes=62, depth=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1af9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ebcc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img_input (InputLayer)          [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 24)   240         img_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 28, 28, 24)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 24)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 12)   2604        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 28, 28, 36)   0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 28, 36)   144         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 28, 28, 36)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 12)   3900        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 48)   0           conv2d_2[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 48)   192         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 28, 28, 12)   5196        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 60)   0           conv2d_3[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 28, 28, 60)   240         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 60)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 12)   6492        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 72)   0           conv2d_4[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 72)   288         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 72)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 12)   7788        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 28, 28, 84)   0           conv2d_5[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 28, 28, 84)   336         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 84)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 28, 28, 12)   9084        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 28, 28, 96)   0           conv2d_6[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 28, 28, 96)   384         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 28, 28, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 12)   10380       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 28, 28, 108)  0           conv2d_7[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 28, 28, 108)  432         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 28, 28, 108)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 96)   10464       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 14, 14, 96)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 14, 14, 96)   384         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 96)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 14, 14, 12)   10380       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 14, 14, 108)  0           conv2d_9[0][0]                   \n",
      "                                                                 average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 14, 14, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 108)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 14, 14, 12)   11676       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 14, 14, 120)  0           conv2d_10[0][0]                  \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 14, 14, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 14, 14, 120)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 14, 14, 12)   12972       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 14, 14, 132)  0           conv2d_11[0][0]                  \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 14, 14, 132)  528         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 14, 14, 132)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 12)   14268       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 14, 14, 144)  0           conv2d_12[0][0]                  \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 14, 14, 144)  576         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 14, 14, 144)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 12)   15564       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 14, 14, 156)  0           conv2d_13[0][0]                  \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 14, 14, 156)  624         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 14, 14, 156)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 14, 12)   16860       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 14, 14, 168)  0           conv2d_14[0][0]                  \n",
      "                                                                 concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 14, 14, 168)  672         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 14, 14, 168)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 14, 14, 12)   18156       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 14, 14, 180)  0           conv2d_15[0][0]                  \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 14, 14, 180)  720         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 14, 14, 180)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 14, 14, 180)  32580       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 7, 7, 180)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 180)    720         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 7, 7, 180)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 48)     8688        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 48)     192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 48)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 12)     5196        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 7, 7, 192)    0           conv2d_18[0][0]                  \n",
      "                                                                 average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 192)    768         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 192)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 7, 48)     9264        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 7, 7, 48)     192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 7, 7, 48)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 7, 7, 12)     5196        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 7, 7, 204)    0           conv2d_20[0][0]                  \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 7, 7, 204)    816         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 7, 7, 204)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 7, 7, 48)     9840        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 7, 7, 48)     192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 7, 7, 48)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 7, 7, 12)     5196        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 7, 7, 216)    0           conv2d_22[0][0]                  \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 7, 7, 216)    864         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 7, 7, 216)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 7, 7, 48)     10416       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 7, 7, 48)     192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 7, 7, 48)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 7, 7, 12)     5196        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 7, 7, 228)    0           conv2d_24[0][0]                  \n",
      "                                                                 concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 7, 7, 228)    912         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 7, 7, 228)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 7, 7, 48)     10992       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 7, 7, 48)     192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 7, 7, 48)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 12)     5196        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 7, 7, 240)    0           conv2d_26[0][0]                  \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 240)    960         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 240)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 7, 7, 48)     11568       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 7, 7, 48)     192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 7, 7, 48)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 7, 7, 12)     5196        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 7, 7, 252)    0           conv2d_28[0][0]                  \n",
      "                                                                 concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 7, 7, 252)    1008        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 7, 7, 252)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 48)     12144       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 48)     192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 48)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 12)     5196        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 7, 7, 264)    0           conv2d_30[0][0]                  \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 264)    1056        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 264)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 264)          0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 62)           16430       global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 329,294\n",
      "Trainable params: 321,806\n",
      "Non-trainable params: 7,488\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7be6340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"model_val_loss.best.hdf5\"\n",
    "checkpoint_acc = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='auto')\n",
    "# Early Stopping\n",
    "earlyStopping_acc = EarlyStopping(monitor='acc', min_delta=0.01, patience=3, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint_acc, earlyStopping_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a31ce2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_optimizer = Adam(lr=1E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model_optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f111ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=model_optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c58f3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8725/8725 [==============================] - 7524s 862ms/step - loss: 0.5463 - accuracy: 0.8320 - val_loss: 0.4365 - val_accuracy: 0.8553\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 2/10\n",
      "8725/8725 [==============================] - 7514s 861ms/step - loss: 0.4151 - accuracy: 0.8582 - val_loss: 0.4190 - val_accuracy: 0.8570\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 3/10\n",
      "8725/8725 [==============================] - 7514s 861ms/step - loss: 0.3910 - accuracy: 0.8646 - val_loss: 0.4388 - val_accuracy: 0.8500\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 4/10\n",
      "8725/8725 [==============================] - 7513s 861ms/step - loss: 0.3768 - accuracy: 0.8680 - val_loss: 0.3973 - val_accuracy: 0.8581\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 5/10\n",
      "8725/8725 [==============================] - 7457s 855ms/step - loss: 0.3672 - accuracy: 0.8708 - val_loss: 0.3806 - val_accuracy: 0.8672\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 6/10\n",
      "8725/8725 [==============================] - 7496s 859ms/step - loss: 0.3603 - accuracy: 0.8723 - val_loss: 0.3597 - val_accuracy: 0.8730\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 7/10\n",
      "8725/8725 [==============================] - 8236s 944ms/step - loss: 0.3545 - accuracy: 0.8736 - val_loss: 0.3730 - val_accuracy: 0.8689\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 8/10\n",
      "8725/8725 [==============================] - 7544s 865ms/step - loss: 0.3505 - accuracy: 0.8749 - val_loss: 0.3585 - val_accuracy: 0.8731\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 9/10\n",
      "8725/8725 [==============================] - 7529s 863ms/step - loss: 0.3465 - accuracy: 0.8759 - val_loss: 0.3600 - val_accuracy: 0.8732\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 10/10\n",
      "8725/8725 [==============================] - 7526s 863ms/step - loss: 0.3431 - accuracy: 0.8769 - val_loss: 0.3629 - val_accuracy: 0.8693\n",
      "WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "3636/3636 [==============================] - 319s 88ms/step - loss: 0.3589 - accuracy: 0.8702\n",
      "\n",
      "Test Accuracy: [0.35894179344177246, 0.8701879382133484]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=64, epochs=10, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=callbacks_list)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('\\nTest Accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8394b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67a051",
   "metadata": {},
   "source": [
    "# Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1498b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce8264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
